---
title: "Regression_analysis"
author: "Street Tree"
date: "`r format(Sys.Date())`"
output:
  pdf_document: default
  html_document:
    fig_width: 8
    fig_height: 5
    fig_caption: true
    toc: true
    toc_float: true
    self_contained: true
---


#0 set up
```{r include=FALSE}
# load packages
library(tidyverse)
library(sf) 
library(mapview)  
library(tidylog) 
library(sfdep)

# install.packages("sfdep")

#working directory
getwd()
list.files()
list.files('../../BaltimoreStreetTreeProject_Large_Data/')
list.files('../../BaltimoreStreetTreeProject_Large_Data/', recursive = TRUE)
```

This file will conduct correlational analyses on combined data of demographics and street tree variables 

#1 Combine dep+ind
```{r include=FALSE}

Dependent <- read_csv('input_data/Dependent_variable_2025-03-14.csv')
Independent<- read_csv('input_data/Independent_variable_2025-03-14.csv')

Combined <- 
  Dependent %>% 
  left_join(Independent, by = "CSA2020") |> 
  select(-geometry)


Combined |> glimpse()
```

#2 Neighborhoods as spatial objects
```{r}

neigh_path <- '../BaltimoreStreetTreeProject_Large_Data/Community_Statistical_Areas_(2020)/Community_Statistical_Areas__2020_.shp'


# https://docs.google.com/document/d/1WIrD624US7UB5cLVfrwTaP8y3QPF0mW7GIHc1mYNmf8/edit?tab=t.0
neighs <- 
  read_sf(  neigh_path
          , as_tibble = TRUE) |> 
  select(CSA2020) |> 
  left_join(Combined, by = 'CSA2020') |> 
  drop_na() |> 
  select(
    # ids
    , CSA2020
    
    # dependent variables
    , rich_tottree        # Richness normalized by total trees
    , Evar            # Evenness
    , AvgDBH_smallmed # Small Tree Average DBH
#    , AvgDBH_med      # Small Tree Average DBH no longer a thing
    , AvgDBH_large    # Large Tree Average DBH
    , percent_filled  # occupancy/stocking/percentage of filled sites
    , totsites        # all tree sites (filled or not)
    , PercGood        # % of trees in good condition
    , PercPoor        # % trees in poor condition
    , PercDead        # % trees dead or stump
    , spave           # beta diversity
    , Perc2.97        # % of trees above threshold 
    
    # independent
    , PercBlk
    , PercWhite
    , mhhi20
    , bahigher20
    , avg_temp
    , PercentImp
    , PopDensity
    , sum_road_length_m
    , vacant20
    ) %>%
  mutate(area_km2 = st_area(.) / 1e+6)


```



# 2 Exploratory Data Analyses
##A maps of predictors
```{r eval=FALSE, include=FALSE}


# neighs |> 
#   select(CSA2010) |> 
#   left_join(
#     neighs |> 
#       st_drop_geometry() |> 
#       select(
#           CSA2010
#         , PercBlk
#         , PercWhite
#         , mhhi20
#         , bahigher19
#         , avg_temp
#         ) |> 
#       pivot_longer(-CSA2010)
#     ) |> 
#   ggplot() + 
#   geom_sf() +
#   facet_wrap(~CSA2010)

neighs |> 
  select(
      CSA2020
    , PercBlk
    , PercWhite
    , mhhi20
    , bahigher20
    , avg_temp
    ) |> 
  pivot_longer(PercBlk : avg_temp) |> 
  st_as_sf() |>  
  ggplot() + 
  geom_sf(aes(fill = value)) +
  facet_wrap(~name)


m1 <- neighs |> mapview::mapview(zcol = 'PercBlk') 
m2 <- neighs |> mapview::mapview(zcol = 'PercWhite') 
m3 <- neighs |> mapview::mapview(zcol = 'mhhi20')
m4 <- neighs |> mapview::mapview(zcol = 'bahigher20')
m5 <- neighs |> mapview::mapview(zcol = 'avg_temp')


m <- leafsync::sync(m1, m2, m3, m4, m5, ncol = 2); rm(m1, m2, m3, m4, m5)
m


```

###B are these dependent variables normally distributed?
```{r}

neighs |> 
  st_drop_geometry() |> 
  select(
      CSA2020
    # dependent variables
    , rich_tottree        # Richness normalized by total trees
    , Evar            # Evenness
    , AvgDBH_smallmed # Small Tree Average DBH
#    , AvgDBH_med      # Small Tree Average DBH no longer a thing
    , AvgDBH_large    # Large Tree Average DBH
    , percent_filled  # occupancy/stocking/percentage of filled sites
    , totsites        # all tree sites (filled or not)
    , PercGood        # % of trees in good condition
    , PercPoor        # % trees in poor condition
    , PercDead        # % trees dead or stump
    , spave           # beta diversity
    , Perc2.97        # % of trees above threshold 
    ) |> 
  pivot_longer(-CSA2020) |> 
  ggplot(aes(value)) +
  geom_density() +
  # scale_x_log10() + # richness should be transformed
  # scale_x_sqrt() + # good for sm_rich_tot
  facet_wrap(~name, scales = 'free') +
  theme_bw(16) +
  NULL

```

# multiple regression
```{r}

# TODO updated to use , percent_filled, richness, Evar, sm_rich_tot, L_rich_tot, PercGood

#     # dependent variables
#       rich_tot        # Richness normalized by total trees
#     , Evar            # Evenness
#     , AvgDBH_small    # Small Tree Average DBH
#     , AvgDBH_med      # Small Tree Average DBH
#     , AvgDBH_large    # Small Tree Average DBH
#     , percent_filled  # occupancy/stocking/percentage of filled sites
#     , all_sites       # all tree sites (filled or not)
#     , PercGood        # % of trees in good condition
#     , PercPoor        # % trees in poor condition
#     , PercDead        # % trees dead or stump
#     , spave           # beta diversity
#     , Perc2.97        # % of trees above threshold 
#     
#     # independent
#     , PercBlk
#     , PercWhite
#     , mhhi20
#     , bahigher20
#     , avg_temp
#     , PercentImp
#     , PopDensity
#     , road_length_m

# # TOO MANY PREDICTORS
# mods <- 
#   neighs |> 
#   nest() |> 
#   mutate(
#     # some mods
#       ols_all_sites      = map(data, ~lm(all_sites      ~ PercBlk + PercWhite + mhhi20 + bahigher20 + avg_temp, .x))
#     , ols_percent_filled = map(data, ~lm(percent_filled ~ PercBlk + PercWhite + mhhi20 + bahigher20 + avg_temp, .x))
#     , ols_sm_rich_tot    = map(data, ~lm(sm_rich_tot    ~ PercBlk + PercWhite + mhhi20 + bahigher20 + avg_temp, .x))
#     , ols_L_rich_tot     = map(data, ~lm(L_rich_tot     ~ PercBlk + PercWhite + mhhi20 + bahigher20 + avg_temp, .x))
#     , ols_PercGood       = map(data, ~lm(PercGood       ~ PercBlk + PercWhite + mhhi20 + bahigher20 + avg_temp, .x))
#     
#     # spatial neighbors, etc.
#     , nbs = map(data, ~st_contiguity(st_geometry(.x)))
#     , wts = map(nbs, st_weights) # , allow_zero = TRUE)
#     # , list_w = map2(nbs, wts, recreate_listw)
#     
#     # some summaries
#     , ols_all_sites_smry      = map(ols_all_sites     , summary)
#     , ols_percent_filled_smry = map(ols_percent_filled, summary)
#     , ols_sm_rich_tot_smry    = map(ols_sm_rich_tot   , summary)
#     , ols_L_rich_tot_smry     = map(ols_L_rich_tot    , summary)
#     , ols_PercGood_smry       = map(ols_PercGood      , summary)
# 
#     # residuals
#     , ols_all_sites_resid      = map(ols_all_sites     , residuals)
#     , ols_percent_filled_resid = map(ols_percent_filled, residuals)
#     , ols_sm_rich_tot_resid    = map(ols_sm_rich_tot   , residuals)
#     , ols_L_rich_tot_resid     = map(ols_L_rich_tot    , residuals)
#     , ols_PercGood_resid       = map(ols_PercGood      , residuals)
#     
#     # test residuals for spatial autocorrelation
#     , ols_all_sites_resid_mi      = pmap(list(ols_all_sites_resid     , nbs, wts), global_moran_perm)
#     , ols_percent_filled_resid_mi = pmap(list(ols_percent_filled_resid, nbs, wts), global_moran_perm)
#     , ols_sm_rich_tot_resid_mi    = pmap(list(ols_sm_rich_tot_resid   , nbs, wts), global_moran_perm)
#     , ols_L_rich_tot_resid_mi     = pmap(list(ols_L_rich_tot_resid    , nbs, wts), global_moran_perm)
#     , ols_PercGood_resid_mi       = pmap(list(ols_PercGood_resid      , nbs, wts), global_moran_perm)
#     )
# 
# 
# mods$ols_all_sites_smry
# mods$ols_percent_filled_smry
# mods$ols_sm_rich_tot_smry
# mods$ols_L_rich_tot_smry
# mods$ols_PercGood_smry
# 
# mods |> 
#   select(ends_with('mi')) |> 
#   rowid_to_column() |> 
#   pivot_longer(-rowid) |> 
#   mutate(mi_test = map(value, broom::tidy)) |> 
#   unnest(mi_test)



  # mutate(crime_pers_area = crime_pers / area
  #        , prost_per_cap = prostitutes / pop1831
  #        , clergy_per_cap = clergy / pop1831
  #        ) |> 
  # nest(data = everything()) |> 
  # mutate(
  #     ols_mod = map(data, ~lm(crime_pers_area ~ wealth + prost_per_cap + clergy_per_cap, .x))
  #   , ols_preds = map(ols_mod, ggeffects::ggpredict)
  #   , ols_smry = map(ols_mod, summary)
  #   , nbs = map(data, ~st_contiguity(st_geometry(.x)))
  #   , wts = map(nbs, st_weights)
  #   , list_w = map2(nbs, wts, recreate_listw)
  #   , ols_resids = map(ols_mod, residuals)
  #   , ols_resids_mi = pmap(list(ols_resids, nbs, wts), global_moran_perm)
  #   , ols_lagrange_all = map2(ols_mod, list_w, test = 'all', spdep::lm.LMtests) # zero.policy=TRUE
  #   # , ols_lagrange_pval = map(ols_lagrange_all, broom::tidy)
  # )
  # 


```


# bivariate regression
```{r}

neighs |> 
  map(~sum(is.na(.))) |> 
  bind_rows() |> 
  t() # missing PercentImp, PopDensity, road_length_m

mods_bi <- 
  neighs |> 
  pivot_longer(cols = PercBlk : vacant20, names_to = 'ind', values_to = 'ind_value') |>
  pivot_longer(cols = rich_tottree : Perc2.97, names_to = 'dep', values_to = 'dep_value') |> 
  select(CSA2020, dep, dep_value, ind, ind_value) |> # just moving geom col to end, reorder
  group_by(ind, dep) |> 
  nest() |> 
  mutate(
    # baseline ols
      ols = map(data, ~lm(dep_value ~ ind_value , .x))
    
    # spatial neighbors, etc., lagged outcome variable
    , nbs = map(data, ~st_contiguity(st_geometry(.x)))
    , wts = map(nbs, st_weights) # , allow_zero = TRUE)
    # , list_w = map2(nbs, wts, recreate_listw)
    # , dep_lag = st_lag(data$dep_value, nbs, wts)
    
    # summary
    , ols_smry = map(ols, summary)
      
    # residuals
    , ols_resid = map(ols, residuals)
    
    # test residuals for spatial autocorrelation
    , ols_resid_mi = pmap(list(ols_resid, nbs, wts), global_moran_perm)
    
    # predictions
    , ols_preds = map(ols, ggeffects::ggpredict)
    
    # calculate 
    ) |> 
  ungroup()


mods_bi$data[[1]]

# extract p-values for autocorrelation
mods_bi |> 
  select(ends_with('mi')) |> 
  mutate(mi_test = map(ols_resid_mi, broom::tidy)) |> 
  unnest(mi_test) |> 
  mutate(sig = ifelse(p.value > 0.05, 'not sig', 'sig')) |> 
  janitor::tabyl(sig)


# mods$ols_all_sites_smry
# mods$ols_percent_filled_smry
# mods$ols_sm_rich_tot_smry
# mods$ols_L_rich_tot_smry
# mods$ols_PercGood_smry

mods_bi |>
  select(dep, ind, ols_preds) |> 
  unnest(ols_preds) |> 
  unnest(ols_preds) |> 
  ggplot(aes(x, predicted)) + 
  geom_line() + 
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.5) + 
  # facet_wrap(~group, scales = 'free') +
  facet_grid(dep~ind, scales = 'free') +
  # theme_bw(16) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)) +
  NULL


```

# bivariate (spatial) regression - make weights *before* nesting
```{r}

(var_alias_lu <- 
  readxl::read_excel("input_data/var_alias_lookup.xlsx") |> 
  # mutate(alias = factor(alias
  #                       , levels = c(
  #                             'Stocking'
  #                           , 'Rel. Richness'
  #                           , 'Evenness'
  #                           , 'Beta Diversity'
  #                           , 'DBH small'
  #                           , 'DBH large'
  #                           , '% target pit'
  #                           , 'Good Condition'
  #                           , 'Poor Condition'
  #                           , 'Dead'
  #                           , 'Percent White'
  #                           , 'Percent Black'
  #                           , 'Income'
  #                           , 'Educational Attainment'
  #                           , 'Vacancy'
  #                           , 'Percent Impervious'
  #                           , 'Pop Density'
  #                           , 'Road length'
  #                           , 'Total NB area'
  #                           , 'Temperature'
  #                           )
  # )) |> 
  arrange(alias) |> 
  select(-alias2))

# # 2x checks requires modes_bi_slag from below to be run
# # totsites is what?
# # what is "Potential Sites"
# mods_bi_slag |> 
#   left_join(
#     var_alias_lu |> filter(var == 'dependent')
#              , by = c('dep' = 'name')) |> 
#   filter(is.na(var))
# 
# 
# mods_bi_slag |> 
#   anti_join(
#     var_alias_lu |> filter(var == 'independent') |> drop_na()
#              , by = c('ind' = 'name')) 

# WHERE's large and small trees, NA, relative richness (rich_tottree) and evenness (Evar)

mods_bi_slag <- 
  neighs |> 
  mutate(
    # spatial neighbors, etc., lagged outcome variable
      nbs = st_contiguity(geometry)
    , wts = st_weights(nbs) # , allow_zero = TRUE)
    , rich_tottree_lag    = st_lag(rich_tottree    , nbs, wts)
    , Evar_lag            = st_lag(Evar            , nbs, wts)
    , AvgDBH_smallmed_lag = st_lag(AvgDBH_smallmed , nbs, wts)
    , AvgDBH_large_lag    = st_lag(AvgDBH_large    , nbs, wts)
    , percent_filled_lag  = st_lag(percent_filled  , nbs, wts)
    , totsites_lag        = st_lag(totsites        , nbs, wts)
    , PercGood_lag        = st_lag(PercGood        , nbs, wts)
    , PercPoor_lag        = st_lag(PercPoor        , nbs, wts)
    , PercDead_lag        = st_lag(PercDead        , nbs, wts)
    , spave_lag           = st_lag(spave           , nbs, wts)
    , Perc2.97_lag        = st_lag(Perc2.97        , nbs, wts)
  ) |> 
  st_drop_geometry() |> 
  select(CSA2020          # id
         # dep 
          , rich_tottree    
          , Evar            
          , AvgDBH_smallmed 
          , AvgDBH_large    
          , percent_filled  
          , totsites        
          , PercGood        
          , PercPoor        
          , PercDead        
          , spave           
          , Perc2.97     

          # lagged dep
          , rich_tottree_lag   
          , Evar_lag           
          , AvgDBH_smallmed_lag
          , AvgDBH_large_lag   
          , percent_filled_lag 
          , totsites_lag       
          , PercGood_lag       
          , PercPoor_lag       
          , PercDead_lag       
          , spave_lag          
          , Perc2.97_lag       
         
          # independent
          , PercBlk
          , PercWhite
          , mhhi20
          , bahigher20
          , avg_temp
          , PercentImp
          , PopDensity
          , sum_road_length_m
          , vacant20
         ) |> 
  pivot_longer(cols = PercBlk : vacant20, names_to = 'ind', values_to = 'ind_value') |> 
  pivot_longer(cols = rich_tottree_lag : Perc2.97_lag, names_to = 'lag', values_to = 'lag_value') |> 
  pivot_longer(cols = percent_filled : Perc2.97, names_to = 'dep', values_to = 'dep_value') |> 
  select(CSA2020, dep, dep_value, ind, ind_value, lag, lag_value) |> # just moving geom col to end, reorder
  # TK HERE
  filter(
    (dep == 'rich_tottree'    & lag == 'rich_tottree_lag')    |
    (dep == 'Evar'            & lag == 'Evar_lag')            |
    (dep == 'AvgDBH_smallmed' & lag == 'AvgDBH_smallmed_lag') |
    (dep == 'AvgDBH_large'    & lag == 'AvgDBH_large_lag')    |
    (dep == 'percent_filled'  & lag == 'percent_filled_lag')  |
    (dep == 'totsites'        & lag == 'totsites_lag')        |
    (dep == 'PercGood'        & lag == 'PercGood_lag')        |
    (dep == 'PercPoor'        & lag == 'PercPoor_lag')        |
    (dep == 'PercDead'        & lag == 'PercDead_lag')        |
    (dep == 'spave'           & lag == 'spave_lag')           |
    (dep == 'Perc2.97'        & lag == 'Perc2.97_lag')
    ) |> 
  group_by(ind, dep) |> 
  nest() |> 
  mutate(
    # baseline ols
    ols = map(data, ~lm(dep_value ~ ind_value, .x))
    
    # summary
    , ols_smry = map(ols, summary)
      
    # # residuals
    # , ols_resid = map(ols, residuals)
    # 
    # # test residuals for spatial autocorrelation
    # , ols_resid_mi = pmap(list(ols_resid, nbs, wts), global_moran_perm)
    
    # predictions
    # , ols_preds = map(ols, ggeffects::ggpredict)
    
    # 'manual' spatial lag model
    , sp_lag = map(data, ~lm(dep_value ~ lag_value + ind_value, .x))
    
    # spatial lag predictions
    , sp_lag_preds = map(sp_lag, ggeffects::ggpredict)
    
    # spatial lag significance
    , sp_lag_sig = map(sp_lag, broom::tidy)
    ) |> 
  ungroup() |> 
  left_join(
      var_alias_lu |> select(name, dep_alias = alias)
    , by = c('dep' = 'name') # PAY ATTENTION
    ) |> 
  left_join(
    var_alias_lu |> select(name, ind_alias = alias)
    , by = c('ind' = 'name') # PAY ATTENTION
  ) #|> 
  # drop_na()
  
mods_bi_slag

mods_bi_slag$data[[1]]

# # extract p-values for autocorrelation
# mods_bi |> 
#   select(ends_with('mi')) |> 
#   mutate(mi_test = map(ols_resid_mi, broom::tidy)) |> 
#   unnest(mi_test) |> 
#   mutate(sig = ifelse(p.value > 0.05, 'not sig', 'sig')) |> 
#   janitor::tabyl(sig)


# mods$ols_all_sites_smry
# mods$ols_percent_filled_smry
# mods$ols_sm_rich_tot_smry
# mods$ols_L_rich_tot_smry
# mods$ols_PercGood_smry

sp_lag_sigs_tbl <-
  mods_bi_slag |> 
  select(dep, ind, sp_lag_sig) |> 
  unnest(sp_lag_sig) |> 
  filter(term == 'ind_value') |> 
  mutate(
    `Sign & Significance` = factor(
      case_when(
          p.value < 0.05 & estimate > 0 ~ 'Positive (p > 0.05)'
        , p.value < 0.05 & estimate < 0 ~ 'Negative (p < 0.05)'
        , p.value >=0.05                ~ 'p > 0.05'
        , TRUE ~ 'ERROR'
        )
      , levels = c('p > 0.05', 'Positive (p > 0.05)', 'Negative (p < 0.05)'))
    ) |> 
  select(dep, ind, `Sign & Significance`)

mods_bi_slag |>
  select(dep, ind, sp_lag_preds, dep_alias, ind_alias) |> 
  unnest(sp_lag_preds) |> 
  unnest(sp_lag_preds) |> 
  filter(group != 'lag_value') |> # cut preds from neighbors
  left_join(sp_lag_sigs_tbl, by = c('dep', 'ind')) |> 
  ggplot(aes(  x
             , predicted
             , color = `Sign & Significance`
             , fill = `Sign & Significance`)
         ) + 
  geom_line() + 
  geom_ribbon(aes(ymin = conf.low, ymax = conf.high), alpha = 0.5) + 
  # facet_wrap(~group, scales = 'free') +
  # facet_grid(dep~ind, scales = 'free') +
  facet_grid(str_wrap(dep_alias, 10) ~ str_wrap(ind_alias, 10), scales = 'free') +
  # theme_bw(16) +
  scale_color_manual(values = c('gray', 'red', 'blue')) +
  scale_fill_manual(values = c('gray', 'red', 'blue')) +
  theme_bw(8) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5)
        , legend.position = 'bottom'
        , strip.text.y = element_text(angle = 0)
        ) +
  labs(  title = 'Relationships betwen independent and dependent variables'
       , subtitle = 'after controling for spatial autocorrelation (spatial lag regression)'
       , x = 'Indepent Variable'
       , y = "Predicted Dependent Variable's Value"
       ) + 
  NULL

ggsave( filename = paste0('figures/Figure_S1_spatial_regression_', Sys.Date(), '.png')
       , width = 6.5
       , height = 7.5)

```


# Condition by pit size
```{r}

no_vacant |> 
  filter(spots....) |> 
  mutate(...pit_area) |> 
  ggplot(aes(CONDITION, pit_area)) +
  geom_boxplot()

```


#3 All correlations
```{r include=FALSE}

(cors_tibble <- 
  Combined |> 
  select(where(is.numeric)) |> # just numeric variables
  cor(use = 'pairwise.complete') |> # instead of drop_na
  data.frame() |> # changing from matrix to dataframe
  rownames_to_column(var = 'var1') |> 
  as_tibble() |> 
  pivot_longer(-var1, names_to = 'var2') |> # make long
  filter(abs(value) !=1) # drop perfect correlations
 ) 

#cors_tibble |> View() # for interactivity

# per group, most correlated
 cors_tibble |> 
   group_by(var1) |> 
   arrange(desc(value)) |> 
   slice(1:5) |> # top five most correlated
   ungroup() #|> View()

```

#4 Sort correlations for r>= |0.4|
```{r include=FALSE}

# filter for correlations higher than .9 (values higher than .89 not correlated with demographics)
cor_0.9 <- cors_tibble %>% 
  filter(value >= 0.9) %>%  
  group_by(var1) 

#filter for correlations r = 0.8-0.89
cor_0.8 <- cors_tibble %>% 
  filter(value >=0.8&value < .9) %>%  
  group_by(var1)

#filter for var1= predicted independent variables and var2 = dependent variables, |r|>= 0.3
cor_filtered <- cors_tibble %>% 
  #filter var1 = independent variables
  filter(var1 =='PercBlk'|var1 =='PercWhite'|
           var1=='mhhi20'|var1=='bahigher19'|
           var1=='avg_temp')%>%
  #filter var2 = dependent variables
  filter(var2=='richness'|var2=='Evar'|var2=='AvgDBH'|var2=='cv'|
           var2=='richness_SM'|var2=='Evar_SM'|var2=='sm_rich_tot'|
           var2=='richness_L'|var2=='Evar_L'|var2=='L_rich_tot'|
           var2=='PercNat'|var2=='avg_temp'|var2=='percent_filled'|var2== 'all_sites'|
           var2== 'PercGood'|var2== 'PercPoor'|var2 == 'PercSmall'|var2 == 'PercMedium'|var2 == 'PercLarge') %>%
  filter(value>=0.4 | value<=-0.4)  
```

#5 First pass scatter plots
```{r echo=FALSE}

Combined |> glimpse()



#richness norm by total trees
Combined |> 
  tidylog::select(#CSA2010 # ID
                   richness_SM # depend
                  , mhhi20 # independents, income
                  , PercWhite # race
                  , PercBlk
                  , bahigher19 # edu
                  , avg_temp
                  ) |> 
  pivot_longer(-richness_SM) |> 
  ggplot(aes(value,richness_SM)) + 
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  geom_smooth(col = 'pink') + 
  facet_wrap(~name, scales = 'free_x'
             , ncol = 3
             ) +
  labs(title = 'Total Number of Trees'
       , subtitle = 'Normalized by Neighborhood Area'
       , captions = 'sources'
       , x = 'predictor'
       , y = 'my outcome of interest (total street trees in this case)'
       ) + 
  theme_bw(14) +
  NULL


```

Scatter plots for correlations that met criteria r>=|0.4| for indep vs dep variables:

# 6 Evenness  
```{r echo=FALSE, message=FALSE, warning=FALSE}
Combined |> 
  tidylog::select(
                   Evar  # depend
                  , avg_temp
                  ) |> 
  pivot_longer(-Evar) |> 
  ggplot(aes(value, Evar)) +
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  labs(x = 'Average Temperature'
       , y = 'Evenness' 
       ) + theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20))
  NULL

cor.test(Combined$avg_temp, Combined$Evar)

#dataset with no outliers

evenness <- Combined %>% 
  filter(Evar < 0.6) %>% 
  select(Evar  # depend
                  , avg_temp)

  ggplot(evenness, aes(avg_temp, Evar)) +
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  labs(x = 'Average Temperature'
       , y = 'Evenness' 
       ) + theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20)) +
  NULL

cor.test(evenness$avg_temp, evenness$Evar)
```

# 12 Avg DBH
```{r echo=FALSE, message=FALSE, warning=FALSE}

Combined |> 
  tidylog::select(
                   AvgDBH  # depend
                  , avg_temp
                  ) |> 
  pivot_longer(-AvgDBH) |> 
  ggplot(aes(value, AvgDBH)) + 
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  # facet_wrap(~name, scales = 'free_x'
  #            , ncol = 3
  #            ) +
  labs( x = 'Average Temperature'
       , y = 'Average DBH'
       ) +   theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20))
  NULL

cor.test(Combined$avg_temp, Combined$AvgDBH)

```

# 13 Percent of Plantable Sites with Trees
```{r echo=FALSE}

Perc_names <- as_labeller(
     c(`PercBlk` = "Percent Black", `PercWhite` = "PercentWhite", 
       `bahigher19` = "Bachelor's or higher"))
Combined |> 
  tidylog::select(
                   percent_filled  # depend
                  , PercBlk
                  , PercWhite
                  , bahigher19
                  ) |> 
  pivot_longer(-percent_filled) |> 
  ggplot(aes(value, percent_filled)) + 
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  facet_wrap(~name, scales = 'free_x'
             , ncol = 3, nrow =1
             , labeller = var_names
             ) +
  labs(
         x = 'Predictor'
       , y = 'Percent Filled'
       ) +   theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20))
  NULL

cor.test(Combined$percent_filled, Combined$PercBlk)
cor.test(Combined$percent_filled, Combined$PercWhite)
cor.test(Combined$percent_filled, Combined$bahigher19)
```

# 17 all sites 
```{r}
var_names <- as_labeller(
     c(`PercBlk` = "% Black", `PercWhite` = "% White",`mhhi20` = "Median Household Income", 
       `bahigher19` = "Bachelor's or higher"))

Combined |> 
  tidylog::select(
                    all_sites  # depend 
                  , PercBlk
                  , PercWhite
                  , mhhi20
                  , bahigher19
                  ) |> 
  pivot_longer(-all_sites) |> 
  ggplot(aes(value, all_sites)) + 
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  facet_wrap(~name, scales = 'free_x'
             , ncol = 2, labeller = var_names
             ) +
  labs(
        x = 'Predictor'
       , y = 'Potential Tree Sites'
       ) + 
  
  theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20))
  NULL

cor.test(Combined$PercBlk, Combined$all_sites)
cor.test(Combined$PercWhite, Combined$all_sites)
cor.test(Combined$mhhi20, Combined$all_sites)
cor.test(Combined$bahigher19, Combined$all_sites)  
```

# 18 Percent Condition
```{r}
var_names <- as_labeller(
     c(`PercBlk` = "% Black", `PercWhite` = "% White",`mhhi20` = "Median Household Income", 
       `bahigher19` = "Bachelor's or higher"))

Combined |> 
  tidylog::select(
                    PercGood  # depend 
                  , PercBlk
                  , PercWhite
                  , mhhi20
                  , bahigher19
                  ) |> 
  pivot_longer(-PercGood) |> 
  ggplot(aes(value, PercGood)) + 
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  facet_wrap(~name, scales = 'free_x'
             , ncol = 2, labeller = var_names
             ) +
  labs(
        x = 'Predictor'
       , y = 'Percent Trees in Good Condition'
       ) + 
  
  theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20))
  NULL
  
cor.test(Combined$PercBlk, Combined$PercGood)
cor.test(Combined$PercWhite, Combined$PercGood)
cor.test(Combined$mhhi20, Combined$PercGood)
cor.test(Combined$bahigher19, Combined$PercGood)


Combined |> 
  tidylog::select(
                    PercPoor  # depend 
                  , PercBlk
                  , PercWhite
                  , mhhi20
                  , bahigher19
                  ) |> 
  pivot_longer(-PercPoor) |> 
  ggplot(aes(value, PercPoor)) + 
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  facet_wrap(~name, scales = 'free_x'
             , ncol = 2, labeller = var_names
             ) +
  labs(
        x = 'Predictor'
       , y = 'Percent Trees in Good Condition'
       ) + 
  
  theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20))
  NULL

cor.test(Combined$PercBlk, Combined$PercPoor)
cor.test(Combined$PercWhite, Combined$PercPoor)
cor.test(Combined$mhhi20, Combined$PercPoor)
cor.test(Combined$bahigher19, Combined$PercPoor)
```

# 20 Perc Filled vs Richness 
```{r}
#SM Richness
Combined |> 
  tidylog::select(
                    sm_rich_tot  # depend 
                  , percent_filled
                  ) |> 
  pivot_longer(-sm_rich_tot) |> 
  ggplot(aes(value, sm_rich_tot)) + 
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  facet_wrap(~name, scales = 'free_x'
             , ncol = 2
             ) +
  labs(
        x = 'Percent Filled'
       , y = 'SM Trees Richness'
       ) + 
  
  theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20))
  NULL
  
  (cor.test(Combined$percent_filled, Combined$sm_rich_tot))
  
# no outlier
filled_richness <- Combined %>% 
  filter(sm_rich_tot < 0.1) %>% 
  select(sm_rich_tot,CSA2010,percent_filled)


ggplot(filled_richness, aes(percent_filled, sm_rich_tot)) + 
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  labs(
        x = 'Percent Filled'
       , y = 'SM Trees Richness'
       ) + 
  
  theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20))

(cor.test(filled_richness$percent_filled, filled_richness$sm_rich_tot))

  NULL
```
  

# 22 Perc Canopy vs Temperature
```{r}
  Combined |> 
  tidylog::select(
                    avg_temp  # depend 
                  , PercCanopy
                  ) |> 
  pivot_longer(-avg_temp) |> 
  ggplot(aes(value, avg_temp)) + 
  geom_point() +
  geom_smooth(method = 'lm') + # forces a linear model
  facet_wrap(~name, scales = 'free_x'
             , ncol = 2
             ) +
  labs(
        x = 'Percent Canopy Coverage'
       , y = 'Average Temperature'
       ) + 
  
  theme_bw() +
  theme(panel.grid=element_blank(),
        text=element_text(size=20))
  NULL
  
(cor.test(Combined$PercCanopy, Combined$avg_temp))
```

